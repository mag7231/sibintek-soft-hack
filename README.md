# sibintek-soft-hackathon

Вот пример полного и подробного `README.md` для твоего проекта с учетом базы данных, дашборда и статистики по времени обработки:

```markdown
# Railway Worker Monitoring Dashboard

## Описание
Проект реализует детекцию, классификацию и трекинг работников на железнодорожной станции на основе видео.  
Основные функции:

1. **Детекция людей и поездов** с использованием кастомного детектора (YOLOv11/аналоги).  
2. **Трекинг работников** с присвоением уникальных идентификаторов (track ID) и сохранением траекторий.  
3. **Классификация работников** по типу (mechanic, worker, cleaner, driver, unknown).  
4. **Запись статистики** в SQLite базу данных (`data/app.db`) для последующего анализа.  
5. **Дашборд** на Streamlit для визуализации статистики: распределение времени по зонам, график активности, события внимания.  
6. **Экспорт CSV** с детальной информацией о работе работников и событиях.

Проект кросс-платформенный (Windows, Linux, MacOS), оформлен в PEP8, снабжен docstrings.

---

## Структура проекта
```
```
.
├─ main.py                 # Точка входа для обработки видео и записи в базу
├─ web/
│   └─ dashboard.py        # Streamlit дашборд для визуализации
├─ src/
│   ├─ detector.py         # Детектор людей и поездов
│   ├─ tracker.py          # Трекинг (AdvancedTracker)
│   ├─ classifier.py       # Классификатор работников
│   └─ database.py         # ORM DatabaseManager и таблицы SQLAlchemy
├─ configs/
│   └─ config.yaml         # Настройки детектора, трекера, классификатора
├─ data/
│   ├─ input/              # Входные видео
│   └─ output/             # Результаты обработки видео
└─ requirements.txt
```


---

## Установка

1. Клонируйте репозиторий:
```bash
git clone https://github.com/yourusername/railway-worker-monitoring.git
cd railway-worker-monitoring
````

2. Установите зависимости:

```bash
pip install -r requirements.txt
```

3. Для ускорения инференса на GPU установите соответствующую версию PyTorch:

```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu126
```

Код автоматически использует GPU, если он доступен.

---

## Использование

### 1. Обработка видео и запись данных в базу

```bash
python main.py --input data/input/video.mp4 --output data/output/result.mp4 --config configs/config.yaml
```

**Аргументы:**

* `--input` — путь к видеофайлу.
* `--output` — путь для сохранения обработанного видео.
* `--config` — путь к конфигурационному файлу (detector, tracker, classifier).

**Что делает main.py:**

1. Создает сессию видео в базе данных.
2. Обрабатывает кадры видео:

   * Детектирует людей и поезда.
   * Трекает людей и присваивает уникальные ID.
   * Классифицирует работников.
   * Сохраняет активности работников (`WorkerActivity`) и события поездов (`TrainEvent`) в базу.
3. Сохраняет видео с визуализацией треков, bounding boxes и ID.
4. Записывает время обработки каждого кадра для отчётности (fps и общее время).

Пример вывода в консоли:

```
Video: 1920x1080, 25 FPS, 3000 frames
Database инициализирована
Создана video session ID=1
Processing video: 100%|████████| 3000/3000 [02:30<00:00, 20.0it/s]
Обработка завершена. Видео: data/output/result.mp4, Session ID: 1
```

В данном примере обработка 3000 кадров заняла ~2 минуты 30 секунд, средняя скорость 20 FPS.

---

### 2. Просмотр статистики через дашборд

Запуск Streamlit:

```bash
streamlit run web/dashboard.py
```

**Функции дашборда:**

* Выбор сессии видео.
* Отображение метрик:

  * Всего работников.
  * Время активности и простоя (active/idle).
  * Распределение времени по зонам.
* График активности работников (timeline).
* События внимания (`AttentionEvent`) с возможностью пометок (`OK`, `No uniform`, `Save crop`).
* Экспорт CSV с детализацией активности работников за выбранный фрагмент кадров.

---

## Конфигурация

Пример `configs/config.yaml`:

```yaml
detector:
  model: yolov11
  confidence_threshold: 0.5

tracker:
  max_lost: 30
  iou_threshold: 0.3

classifier:
  model_name: hf-hub:Marqo/marqo-fashionCLIP
  use_fine_tuned: false
  classify_every_n_frames: 5
```

---

## Техническая реализация

* **Детекция и трекинг:** YOLOv11, AdvancedTracker для сохранения траекторий.
* **Классификация:** Используется pretrained модель или fine-tuned для типа работников.
* **База данных:** SQLite (`data/app.db`) через SQLAlchemy ORM. Таблицы:

  * `video_sessions` — сессии видео.
  * `worker_activities` — временные метки и зоны работников.
  * `train_events` — события прибытия/отбытия поездов.
  * `attention_events` — события, требующие внимания.
* **Отчетность по времени:** каждый кадр обрабатывается с записью delta времени (`time_delta = 1/fps`) для анализа нагрузки и скорости.

---

## Результаты

1. Обработанное видео с bounding boxes и ID работников (`data/output/result.mp4`).
2. Заполненная база данных `app.db` с активностями и событиями.
3. Дашборд для визуализации и анализа.
4. Возможность экспортировать CSV с деталями по кадрам и зонам.

---

## Возможные улучшения

* Поддержка batch processing для ускорения обработки длинных видео.
* Дообучение классификатора для специфических типов работников.
* Экспорт модели в ONNX/TensorRT для ускоренного инференса на CPU/GPU.
* Автоматическая генерация отчетов по времени обработки, активности и событиям.
* Добавление аналитики с графиками времени пребывания работников в разных зонах.

```
