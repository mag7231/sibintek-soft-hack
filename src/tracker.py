# src/tracker.py

import numpy as np
import cv2
from collections import defaultdict
from typing import List, Dict, Tuple
import torch


class ReIDFeatureExtractor:
    """
    –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ appearance features –¥–ª—è ReID.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–æ—Å—Ç—É—é CNN –∏–ª–∏ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –æ–¥–µ–∂–¥—ã.
    """
    
    def __init__(self, model_type='resnet50'):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
        
        Args:
            model_type: —Ç–∏–ø –º–æ–¥–µ–ª–∏ ('simple', 'resnet50', 'osnet')
        """
        self.model_type = model_type
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º color histogram + HOG
        # –í –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ –º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ OSNet –∏–ª–∏ ResNet50
        print(f"ReID Feature Extractor –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {model_type} –Ω–∞ {self.device}")
    
    def extract_features(self, frame: np.ndarray, bbox: List[float]) -> np.ndarray:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ appearance features –∏–∑ bbox.
        
        Args:
            frame: –ø–æ–ª–Ω—ã–π –∫–∞–¥—Ä
            bbox: [x1, y1, x2, y2]
            
        Returns:
            feature_vector: numpy array —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        """
        x1, y1, x2, y2 = map(int, bbox)
        
        # Crop person region
        person_crop = frame[y1:y2, x1:x2]
        
        if person_crop.size == 0:
            return np.zeros(256)  # –ü—É—Å—Ç–æ–π –≤–µ–∫—Ç–æ—Ä –µ—Å–ª–∏ crop –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π
        
        # Resize to fixed size
        person_crop = cv2.resize(person_crop, (64, 128))
        
        # Extract color histogram (RGB, 8 bins per channel = 512 dims)
        color_hist = self._extract_color_histogram(person_crop)
        
        # Extract HOG features (–º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ matching)
        # hog_features = self._extract_hog(person_crop)
        
        # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
        features = color_hist
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        features = features / (np.linalg.norm(features) + 1e-6)
        
        return features
    
    def _extract_color_histogram(self, image: np.ndarray, bins=8) -> np.ndarray:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–≤–µ—Ç–æ–≤–æ–π –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã.
        """
        hist_features = []
        
        for channel in range(3):  # BGR
            hist = cv2.calcHist([image], [channel], None, [bins], [0, 256])
            hist = hist.flatten()
            hist_features.extend(hist)
        
        return np.array(hist_features)
    
    def compute_similarity(self, feat1: np.ndarray, feat2: np.ndarray) -> float:
        """
        –í—ã—á–∏—Å–ª–µ–Ω–∏–µ similarity –º–µ–∂–¥—É –¥–≤—É–º—è feature vectors.
        
        Args:
            feat1, feat2: feature vectors
            
        Returns:
            similarity score (0-1, –≥–¥–µ 1 = –∏–¥–µ–Ω—Ç–∏—á–Ω—ã)
        """
        # Cosine similarity
        similarity = np.dot(feat1, feat2)
        return max(0.0, similarity)  # Clip to [0, 1]


class AdvancedTracker:
    """
    –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —Ç—Ä–µ–∫–µ—Ä —Å ReID –¥–ª—è –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–≥–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è.
    –û—Å–Ω–æ–≤–∞–Ω –Ω–∞ BoT-SORT —Å custom ReID logic.
    """
    
    def __init__(self, config: dict):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–∫–µ—Ä–∞.
        
        Args:
            config: —Å–ª–æ–≤–∞—Ä—å —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ —Ç—Ä–µ–∫–∏–Ω–≥–∞
        """
        self.config = config
        
        # ReID —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä
        self.reid_extractor = ReIDFeatureExtractor()
        
        # –ê–∫—Ç–∏–≤–Ω—ã–µ —Ç—Ä–µ–∫–∏
        self.active_tracks = {}  # track_id -> track_info
        
        # –ü–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ —Ç—Ä–µ–∫–∏ (–¥–ª—è long-term ReID)
        self.lost_tracks = {}  # track_id -> track_info
        
        # –°—á–µ—Ç—á–∏–∫ ID
        self.next_id = 1
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        self.track_buffer = config.get('track_buffer', 120)
        self.long_term_buffer = config.get('long_term_buffer', 9000)
        self.appearance_thresh = config.get('appearance_thresh', 0.25)
        self.match_thresh = config.get('match_thresh', 0.8)
        self.reid_confidence = config.get('reid_confidence', 0.7)
        
        print(f"AdvancedTracker –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω:")
        print(f"  - Track buffer: {self.track_buffer} frames")
        print(f"  - Long-term buffer: {self.long_term_buffer} frames")
        print(f"  - ReID threshold: {self.appearance_thresh}")
    
    def update(self, frame: np.ndarray, detections: List[Dict]) -> List[Dict]:
        """
        –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ–∫–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ–≤—ã—Ö –¥–µ—Ç–µ–∫—Ü–∏–π.
        
        Args:
            frame: —Ç–µ–∫—É—â–∏–π –∫–∞–¥—Ä
            detections: —Å–ø–∏—Å–æ–∫ –¥–µ—Ç–µ–∫—Ü–∏–π [{bbox, conf, class_id, class_name}, ...]
            
        Returns:
            tracks: —Å–ø–∏—Å–æ–∫ —Ç—Ä–µ–∫–æ–≤ —Å –Ω–∞–∑–Ω–∞—á–µ–Ω–Ω—ã–º–∏ ID
        """
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ª—é–¥–µ–π
        person_detections = [d for d in detections if d['class_name'] == 'person']
        
        if len(person_detections) == 0:
            # –û–±–Ω–æ–≤–ª—è–µ–º lost —Ç—Ä–µ–∫–∏
            self._update_lost_tracks()
            return []
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º ReID features –¥–ª—è –≤—Å–µ—Ö –¥–µ—Ç–µ–∫—Ü–∏–π
        detection_features = []
        for det in person_detections:
            features = self.reid_extractor.extract_features(frame, det['bbox'])
            detection_features.append(features)
        
        # Matching —Å –∞–∫—Ç–∏–≤–Ω—ã–º–∏ —Ç—Ä–µ–∫–∞–º–∏
        matched_tracks, unmatched_detections, unmatched_tracks = self._match_detections_to_tracks(
            person_detections, detection_features
        )
        
        # –û–±–Ω–æ–≤–ª—è–µ–º matched —Ç—Ä–µ–∫–∏
        for track_id, det_idx in matched_tracks:
            det = person_detections[det_idx]
            features = detection_features[det_idx]
            self._update_track(track_id, det, features, frame)
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ —Ç—Ä–µ–∫–∏ –¥–ª—è unmatched detections
        # –°–Ω–∞—á–∞–ª–∞ –ø—ã—Ç–∞–µ–º—Å—è match —Å lost tracks (ReID)
        for det_idx in unmatched_detections:
            det = person_detections[det_idx]
            features = detection_features[det_idx]
            
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –≤ lost tracks
            matched_lost_id = self._match_with_lost_tracks(features)
            
            if matched_lost_id is not None:
                # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç—Ä–µ–∫ –∏–∑ lost
                self._reactivate_track(matched_lost_id, det, features, frame)
            else:
                # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Ç—Ä–µ–∫
                self._create_new_track(det, features, frame)
        
        # –ü–µ—Ä–µ–≤–æ–¥–∏–º unmatched active —Ç—Ä–µ–∫–∏ –≤ lost
        for track_id in unmatched_tracks:
            self._move_to_lost(track_id)
        
        # –û—á–∏—Å—Ç–∫–∞ old lost tracks
        self._cleanup_lost_tracks()
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∞–∫—Ç–∏–≤–Ω—ã–µ —Ç—Ä–µ–∫–∏
        return self._get_active_tracks_output()
    
    def _match_detections_to_tracks(
        self, 
        detections: List[Dict], 
        features: List[np.ndarray]
    ) -> Tuple[List, List, List]:
        """
        Matching –¥–µ—Ç–µ–∫—Ü–∏–π —Å –∞–∫—Ç–∏–≤–Ω—ã–º–∏ —Ç—Ä–µ–∫–∞–º–∏.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç IoU + ReID appearance similarity.
        """
        if len(self.active_tracks) == 0:
            return [], list(range(len(detections))), []
        
        # Cost matrix: [num_tracks, num_detections]
        track_ids = list(self.active_tracks.keys())
        cost_matrix = np.zeros((len(track_ids), len(detections)))
        
        for i, track_id in enumerate(track_ids):
            track = self.active_tracks[track_id]
            track_bbox = track['bbox']
            track_features = track['features']
            
            for j, det in enumerate(detections):
                det_bbox = det['bbox']
                det_features = features[j]
                
                # IoU cost
                iou = self._calculate_iou(track_bbox, det_bbox)
                
                # Appearance cost (ReID)
                appearance_sim = self.reid_extractor.compute_similarity(
                    track_features, det_features
                )
                
                # Combined cost (lower is better)
                # –ò–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º, —á—Ç–æ–±—ã –≤—ã—Å–æ–∫–∏–π IoU –∏ similarity –¥–∞–≤–∞–ª–∏ –Ω–∏–∑–∫—É—é —Å—Ç–æ–∏–º–æ—Å—Ç—å
                cost = 1.0 - (0.5 * iou + 0.5 * appearance_sim)
                cost_matrix[i, j] = cost
        
        # Hungarian matching
        from scipy.optimize import linear_sum_assignment
        
        matched_indices = linear_sum_assignment(cost_matrix)
        matched_tracks = []
        
        matched_det_indices = set()
        matched_track_indices = set()
        
        for track_idx, det_idx in zip(*matched_indices):
            cost = cost_matrix[track_idx, det_idx]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º threshold
            if cost < (1.0 - self.match_thresh):
                track_id = track_ids[track_idx]
                matched_tracks.append((track_id, det_idx))
                matched_det_indices.add(det_idx)
                matched_track_indices.add(track_idx)
        
        # Unmatched
        unmatched_detections = [i for i in range(len(detections)) if i not in matched_det_indices]
        unmatched_tracks = [track_ids[i] for i in range(len(track_ids)) if i not in matched_track_indices]
        
        return matched_tracks, unmatched_detections, unmatched_tracks
    
    def _match_with_lost_tracks(self, features: np.ndarray) -> int:
        """
        Matching —Å lost tracks –∏—Å–ø–æ–ª—å–∑—É—è —Ç–æ–ª—å–∫–æ ReID.
        """
        best_match_id = None
        best_similarity = 0.0
        
        for track_id, track in self.lost_tracks.items():
            track_features = track['features']
            similarity = self.reid_extractor.compute_similarity(features, track_features)
            
            if similarity > best_similarity and similarity > self.reid_confidence:
                best_similarity = similarity
                best_match_id = track_id
        
        return best_match_id
    
    def _calculate_iou(self, bbox1: List[float], bbox2: List[float]) -> float:
        """
        –í—ã—á–∏—Å–ª–µ–Ω–∏–µ IoU –º–µ–∂–¥—É –¥–≤—É–º—è bbox.
        """
        x1_1, y1_1, x2_1, y2_1 = bbox1
        x1_2, y1_2, x2_2, y2_2 = bbox2
        
        # Intersection
        x1_i = max(x1_1, x1_2)
        y1_i = max(y1_1, y1_2)
        x2_i = min(x2_1, x2_2)
        y2_i = min(y2_1, y2_2)
        
        if x2_i < x1_i or y2_i < y1_i:
            return 0.0
        
        intersection = (x2_i - x1_i) * (y2_i - y1_i)
        
        # Union
        area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
        area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
        union = area1 + area2 - intersection
        
        return intersection / (union + 1e-6)
    
    def _create_new_track(self, detection: Dict, features: np.ndarray, frame: np.ndarray):
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —Ç—Ä–µ–∫–∞."""
        track_id = self.next_id
        self.next_id += 1
        
        self.active_tracks[track_id] = {
            'id': track_id,
            'bbox': detection['bbox'],
            'conf': detection['conf'],
            'features': features,
            'age': 1,
            'hits': 1,
            'time_since_update': 0,
            'history': [detection['bbox']],
            'first_seen_frame': frame.copy()  # –î–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        }
    
    def _update_track(self, track_id: int, detection: Dict, features: np.ndarray, frame: np.ndarray):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ç—Ä–µ–∫–∞."""
        track = self.active_tracks[track_id]
        track['bbox'] = detection['bbox']
        track['conf'] = detection['conf']
        
        # –û–±–Ω–æ–≤–ª—è–µ–º features (EMA –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è)
        alpha = 0.9
        track['features'] = alpha * track['features'] + (1 - alpha) * features
        track['features'] = track['features'] / (np.linalg.norm(track['features']) + 1e-6)
        
        track['hits'] += 1
        track['time_since_update'] = 0
        track['history'].append(detection['bbox'])
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
        if len(track['history']) > 30:
            track['history'] = track['history'][-30:]
    
    def _reactivate_track(self, track_id: int, detection: Dict, features: np.ndarray, frame: np.ndarray):
        """–†–µ–∞–∫—Ç–∏–≤–∞—Ü–∏—è —Ç—Ä–µ–∫–∞ –∏–∑ lost."""
        track = self.lost_tracks.pop(track_id)
        track['bbox'] = detection['bbox']
        track['conf'] = detection['conf']
        track['time_since_update'] = 0
        
        # –û–±–Ω–æ–≤–ª—è–µ–º features
        alpha = 0.8
        track['features'] = alpha * track['features'] + (1 - alpha) * features
        track['features'] = track['features'] / (np.linalg.norm(track['features']) + 1e-6)
        
        self.active_tracks[track_id] = track
        
        print(f"–¢—Ä–µ–∫ #{track_id} —Ä–µ–∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω —á–µ—Ä–µ–∑ ReID!")
    
    def _move_to_lost(self, track_id: int):
        """–ü–µ—Ä–µ–≤–æ–¥ —Ç—Ä–µ–∫–∞ –≤ lost."""
        track = self.active_tracks.pop(track_id)
        track['time_since_update'] = 0
        track['lost_frame_count'] = 0
        self.lost_tracks[track_id] = track
    
    def _update_lost_tracks(self):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—á–µ—Ç—á–∏–∫–æ–≤ –¥–ª—è lost —Ç—Ä–µ–∫–æ–≤."""
        for track in self.lost_tracks.values():
            track['lost_frame_count'] += 1
    
    def _cleanup_lost_tracks(self):
        """–£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö lost —Ç—Ä–µ–∫–æ–≤."""
        to_remove = []
        
        for track_id, track in self.lost_tracks.items():
            if track['lost_frame_count'] > self.long_term_buffer:
                to_remove.append(track_id)
        
        for track_id in to_remove:
            self.lost_tracks.pop(track_id)
            print(f"  üóëÔ∏è –¢—Ä–µ–∫ #{track_id} —É–¥–∞–ª–µ–Ω (–ø—Ä–µ–≤—ã—à–µ–Ω long-term buffer)")
    
    def _get_active_tracks_output(self) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç—Ä–µ–∫–æ–≤ –¥–ª—è –≤—ã–≤–æ–¥–∞."""
        output = []
        
        for track_id, track in self.active_tracks.items():
            track['time_since_update'] += 1
            
            output.append({
                'track_id': track_id,
                'bbox': track['bbox'],
                'conf': track['conf'],
                'class_name': 'person',
                'hits': track['hits'],
                'age': track.get('age', 1)
            })
        
        return output